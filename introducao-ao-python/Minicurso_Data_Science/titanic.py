#Segundo dia mini curso data science 04/05/2023
#Por Alecio Nunes

#dados titanic: https://drive.google.com/drive/folders/1dWD5RT0Ak_xeQ1W27ShQedNV1n2BGJpH?usp=sharing
# -*- coding: utf-8 -*-
"""Titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HDnnaIsm3T2jZv-F-5tRP4QyPzDDHRO8
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import cross_val_score
from sklearn.pipeline import Pipeline
from sklearn import model_selection
from sklearn.feature_selection import chi2
from sklearn.model_selection import train_test_split
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from warnings import simplefilter
simplefilter(action='ignore', category=FutureWarning)
# %matplotlib inline

path_test = "/content/drive/MyDrive/Data/titanic/test.csv"
path_train = "/content/drive/MyDrive/Data/titanic/train.csv"

train = pd.read_csv(path_train)
test = pd.read_csv(path_test)

train.head()

train.describe()

train.describe(include=['O'])

train.info()

# Qual a quantidade de sobreviventes do Titanic?
survived = train[train['Survived'] == 1]
not_survived = train[train['Survived'] == 0]

print(f'Total number of passengers: {len(train)}')
print(f'Survived: {len(survived)}')
print(f'Not Survived: {len(not_survived)}')

# Total de passageiros por classe.
train.groupby('Pclass').size()

# Número de passageiros de cada classe e seus respectivos sexos.
pd.crosstab(train['Pclass'],train['Sex'])

# Número de sobreviventes por classe.
# 0 - not survived    1 - survived
pd.crosstab(train['Pclass'],train['Survived'])

# Média de sobreviventes por classe.
train[['Pclass','Survived']].groupby(['Pclass'], as_index = False).mean().sort_values(by='Survived',ascending=False)

sns.countplot(x='Survived', hue='Pclass', data=train, palette='rainbow')

# Quantidade de passageiros de acordo com o sexo.
# female = feminino, male = masculino
train['Sex'].value_counts()

# Número de sobreviventes por sexo.
# 0 - not survived    1 - survived
pd.crosstab(train['Sex'],train['Survived'])

# Média de sobreviventes de cada sexo.
train[['Sex','Survived']].groupby(['Sex'], as_index = False).mean().sort_values(by='Survived',ascending=False)

sns.countplot(x='Survived' ,hue='Sex', data=train, palette='rainbow')

train.head()

# Número de passageiros de acordo com a país de embarque.
# S-> Southampton (Reino Unido)
# C-> Cherbourg-Octeville (França)
# Q-> Queenstown (Irlanda)
train['Embarked'].value_counts()

# Número de sobreviventes por país de embarque.
# 0 - not survived    1 - survived
pd.crosstab(train['Embarked'],train['Survived'])

# Média de sobreviventes de acordo com o país que ele embarcou.
train[['Embarked','Survived']].groupby(['Embarked'], as_index = False).mean().sort_values(by='Survived',ascending=False)

sns.barplot(x='Embarked', y='Survived', data=train, palette='rainbow')

# Número de pais e filhos viajando com o passageiro.
train['Parch'].value_counts()

# Número de sobreviventes de acordo com a quantidade de pais e filhos viajando com o passageiro.
# 0 - not survived    1 - survived
pd.crosstab(train['Parch'],train['Survived'])

# Média de sobrevivência com base no número de pais/ filhos que o passageiro tinha no navio.
train[['Parch','Survived']].groupby(['Parch'], as_index = False).mean().sort_values(by='Survived',ascending=False)

sns.barplot(x='Parch', y='Survived', data=train, palette='rainbow')

# Número de irmãos e cônjuges viajando com o passageiro.
train['SibSp'].value_counts()

# Número de sobreviventes de acordo com a quantidade de irmãos e cônjuges viajando com o passageiro.
# 0 - not survived    1 - survived
pd.crosstab(train['SibSp'],train['Survived'])

# Média de sobrevivência com base no número de irmãos e cônjuges que o passageiro tinha no navio.
train[['SibSp','Survived']].groupby(['SibSp'], as_index = False).mean().sort_values(by='Survived',ascending=False)

sns.barplot(x='SibSp', y='Survived', data=train, palette='rainbow')

# Distribuição das idades.
plt.figure(figsize=(12,6))
plt.subplot(1,2,1)
fig = train.Age.hist(bins=25)
fig.set_title('Distribuição da idade')

# Distribuição dos valores da passagem.
plt.figure(figsize=(12,6))
plt.subplot(1,2,2)
fig = train.Fare.hist(bins=25)
fig.set_title('Distribuição do valor da passagem')

# Matriz de correlação.
# Possibilita a análise simultânea da associação entre variáveis.
plt.figure(figsize=(15,6))
sns.heatmap(train.drop('PassengerId',axis=1).corr(), vmax=0.6, square=True, annot=True)

train.shape

# Verificando a quantidade de valores nulos no dataset de treino.
train.isnull().sum().sort_values(ascending=False)

# Verificando a quantidade de valores nulos no dataset de teste.
test.isnull().sum().sort_values(ascending=False)

# Preenchendo os valores nulos da coluna 'Age'.
for dataset in train:
    train['Age'].fillna(train['Age'].mean(), inplace=True)

# Preenchendo os valores nulos da coluna 'Age'.
for dataset in train:
    train['Fare'].fillna(train['Fare'].mean(), inplace=True)

# A coluna possui um número bem pequeno de valores faltantes,
# então podemos preencher-la com o valor mais frequente, 
# Variável que mais se repete na coluna 'Embarked'
train['Embarked'].describe()

# Preenchendo os valores nulos da coluna 'Embarked'.
top = 'S'
for dataset in train:
    train['Embarked'] = train['Embarked'].fillna(top)

train.isnull().sum().sort_values(ascending=False)

train.head()

train1 = train.copy()

labels = train1['Embarked'].astype('category').cat.categories.tolist()
replace_map_comp = {'Embarked' : {k: v for k,v in zip(labels, list(range(1,len(labels)+1)))}}

print(replace_map_comp)

train1.replace(replace_map_comp, inplace=True)

train1.head()

labels = train1['Sex'].astype('category').cat.categories.tolist()
replace_map_comp = {'Sex' : {k: v for k,v in zip(labels, list(range(1,len(labels)+1)))}}

print(replace_map_comp)

train1.replace(replace_map_comp, inplace=True)

# Vamos unir a coluna 'SibSp' e 'Parch' para criar uma nova coluna 'Family'.
# Tudo indica que essas duas colunas juntas nos dão o número de membros de uma mesma família.
for dataset in train1:
    train1['Family'] = train1['SibSp'] + train1['Parch'] + 1
    
# Média de sobrevivência com base no número de membros da família no navio. 
train1[['Family','Survived']].groupby(['Family'], as_index = False).mean().sort_values(by='Survived',ascending=False)

sns.barplot(x='Family', y='Survived', data=train1, palette='rainbow')

# Vamos verificar se quem viajava sozinho tinha mais chance de sobreviver.
for dataset in train1:
    train1['Alone'] = train1['Family'].apply(lambda x: x if x == 1 else 0)

# Média de sobrevivência com base no número de membros da família no navio.
train1[['Alone','Survived']].groupby(['Alone'], as_index = False).mean().sort_values(by='Survived',ascending=False)

sns.barplot(x='Alone', y='Survived', data=train1, palette='rainbow')

# Verificando os Outliers
# Os valores fora da barreira externa são caracterizados como Outliers.
sns.boxplot(data = train1.drop('PassengerId',axis=1), orient= 'h')

# Quartil inferior e superior coluna 'Age'
def quartil():
    Q1 = train1['Age'].quantile(q= 0.25)
    Q3 = train1['Age'].quantile(q= 0.75)
    print(f'Q1 = {Q1} e Q3 = {Q3}')
    # Calculando a barreira externa.
    amp = Q3 - Q1
    limite_max = Q3 + 3 * amp
    limite_min = Q1 - 3 * amp
    print(f'Os Outliers da coluna Age estão entre {limite_min} e {limite_max}')
quartil()

train2 = train1.copy()

# Substituindo os valores.
for dataset in train2:
    train2['Age'] = np.where(train2['Age'] > 73, 73, train2['Age'])

# Quartil inferior e superior coluna 'Fare'
def quartil():
    Q1 = train2['Fare'].quantile(q= 0.25)
    Q3 = train2['Fare'].quantile(q= 0.75)
    print(f'Q1 = {Q1} e Q3 = {Q3}')
    # Calculando a barreira externa.
    amp = Q3 - Q1
    limite_max = Q3 + 3 * amp
    limite_min = Q1 - 3 * amp
    print(f'Os Outliers da coluna Fare estão entre {limite_max} e {limite_min}')
quartil()

# Substituindo os valores.
for dataset in train2:
    train2['Fare'] = np.where(train2['Fare'] > 99, 99, train2['Fare'])

# Visualização após o tratamento dos Outliers.
# Deixarei alguns Outliers para obtermos um modelo mais generalista.
sns.boxplot(data = train2.drop('PassengerId',axis=1), orient= 'h')

train2.head()

train2.columns

train3 = train2[['Survived', 'Pclass', 'Sex', 'Age','Embarked', 'Family', 'Alone']]

train3.head()

X = train3[['Pclass', 'Sex', 'Age','Embarked', 'Family', 'Alone']]
y = train3[['Survived']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=25)

### Naive Bayes ###

# Abordagem probabilística (Teorema de Bayes)
gaussian = GaussianNB()
gaussian.fit(X_train, y_train)
prev_gaussian = gaussian.predict(X_test)
result_train = gaussian.score(X_train, y_train)

result_train

### LogisticRegression ###

logreg = LogisticRegression()
logreg.fit(X_train, y_train)
prev_logreg = logreg.predict(X_test)
result_train = logreg.score(X_train, y_train)
result_train

### Decision Tree ###

decision_tree = DecisionTreeClassifier(criterion='entropy', random_state=7)
decision_tree.fit(X_train,y_train)
prev_tree = decision_tree.predict(X_test)
result_train = decision_tree.score(X_train, y_train)
result_train

### KNN ###

knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p = 2)
knn.fit(X_train,y_train)
prev_knn = knn.predict(X_test)
result_train = knn.score(X_train, y_train)
result_train

### Random Forest ###

random_forest = RandomForestClassifier(n_estimators=200, criterion='entropy', random_state=7)
random_forest.fit(X_train,y_train)
prev_random = random_forest.predict(X_test)
result_train = random_forest.score(X_train, y_train)
result_train

### XGBoost ###

xboost = XGBClassifier()
xboost.fit(X_train, y_train)
prev_xboost = xboost.predict(X_test)
result_train = xboost.score(X_train, y_train)
result_train

### Support vector machines (SVM) ###

svc = SVC(kernel = 'rbf', random_state = 7, C = 10.0, gamma='auto')
svc.fit(X_train,y_train)
previsoes = svc.predict(X_test)
result_train = svc.score(X_train, y_train)
result_train





















